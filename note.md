# 调参结论
1. 在BertLinearModel和BertSaModel中，Roberta-large的效果未比原版有明显提升
2. sa模型容易过早收敛（3epoch之内），可以分层设置并降低学习率（1e5）、减小epoch（4）

# 模型说明
| 模型              | 说明                             |
| ----------------- | -------------------------------- |
| `20230415-235947` | bertLinear, score=0.661048       |
| `20230416-130044` | `20230415-235947`的nodev版本     |
| `20230418-214640` | robertaLinear, score=0.6713      |
| `20230418-215427` | robertaLargeLinear, score=0.6712 |
| `20230418-230201` | `20230418-214640`的nodev版本     |
| `20230420-003434` | robertaLinear, s_ner=0.8291      |
| `20230420-125842` | robertaLargeLinear, s_ner=0.8339 |
| `20230420-135843` | robertaLinear, s_sa=0.5635       |
| `20230421-161347` | robertaGruAttn，s_sa=0.5660      |
| `20230421-195856` | `20230420-125842`的nodev版本     |
| `20230421-200024` | `20230421-161347`的nodev版本     |
| `20230423-114228` | robertaGruAttn，s_sa=0.5746      |
| `20230423-131435` | `20230423-114228`的nodev版本     |
| `20230427-162822` | robertaLargePrompt, s_sa=0.5798  |
| `20230427-183628` | `20230427-162822`的nodev版本     |

# 提交结果

| result              | score   | 备注                                         |
| ------------------- | ------- | -------------------------------------------- |
| `linear1.csv`       | 0.64073 |                                              |
| `linear2.csv`       | 0.614   |                                              |
| `linear_nodev.csv`  | 0.66618 | `20230416-130044`                            |
| `linear_nodev1.csv` | 0.67381 | `20230418-230201`                            |
| `ensembled.csv`     | 0.70061 | `20230421-195856(18)`和`20230421-200024(17)` |
| `ensembled2.csv`    | 0.68066 | `20230421-195856(18)`和`20230423-131435(6)`  |
| `ensembled3.csv`    | 0.68228 | `20230421-195856(18)`和`20230423-114228(11)` |
| `ensembled4.csv`    | 0.68722 | `20230421-195856(18)`和`20230427-183628(5)`  |
| `ensembled5.csv`    | 0.6572  | `20230421-195856(18)`和`20230427-162822(4)`  |

# 可能改进的方向

1. - [ ] 单个字母被tokenizer变为`[UNK]`，如19W可以手动转成19万
2. - [x] 尝试使用别的模型如roberta
3. - [x] 为不同的层设定不同的学习率
